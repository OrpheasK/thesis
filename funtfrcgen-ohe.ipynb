{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:20.251284Z",
     "iopub.status.busy": "2021-02-15T21:07:20.250617Z",
     "iopub.status.idle": "2021-02-15T21:07:26.248116Z",
     "shell.execute_reply": "2021-02-15T21:07:26.248629Z"
    },
    "papermill": {
     "duration": 6.012023,
     "end_time": "2021-02-15T21:07:26.248814",
     "exception": false,
     "start_time": "2021-02-15T21:07:20.236791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "from math import trunc\n",
    "from tensorflow import keras\n",
    "from keras.utils import np_utils, plot_model, to_categorical\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:26.266495Z",
     "iopub.status.busy": "2021-02-15T21:07:26.265880Z",
     "iopub.status.idle": "2021-02-15T21:07:26.300409Z",
     "shell.execute_reply": "2021-02-15T21:07:26.300926Z"
    },
    "papermill": {
     "duration": 0.043957,
     "end_time": "2021-02-15T21:07:26.301083",
     "exception": false,
     "start_time": "2021-02-15T21:07:26.257126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(dim_o, dim_q, dim_p, n_units):\n",
    "\t# define training encoder\n",
    "\tenc_in_o = Input(shape=(None, dim_o))\n",
    "\tenc_in_q = Input(shape=(None, dim_q))\n",
    "\tenc_in_p = Input(shape=(None, dim_p))\n",
    "\tencoder_inputs = concatenate([enc_in_o, enc_in_q, enc_in_p])\n",
    "\tencoder = LSTM(n_units, return_state=True)\n",
    "\tencoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\tencoder_states = [state_h, state_c]\n",
    "\t\n",
    "\t# define training decoder\n",
    "\tdec_in_o = Input(shape=(None, dim_o))\n",
    "\tdec_in_q = Input(shape=(None, dim_q))\n",
    "\tdec_in_p = Input(shape=(None, dim_p))\n",
    "\tdecoder_inputs = concatenate([dec_in_o, dec_in_q, dec_in_p])\n",
    "\tdecoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "\tdecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\tdec_dense_o = Dense(dim_o, activation='softmax', name='tr_out_o')\n",
    "\tdec_dense_q = Dense(dim_q, activation='softmax', name='tr_out_q')\n",
    "\tdec_dense_p = Dense(dim_p, activation='softmax', name='tr_out_p')\n",
    "\t#out_o = Dense(1, activation='relu', name='tr_out_o')(decoder_outputs)#act relu\n",
    "\t#out_q = Dense(1, activation='sigmoid', name='tr_out_q')(decoder_outputs)\n",
    "\t#out_p = Dense(dim_p, activation='softmax', name='tr_out_p')(decoder_outputs)\n",
    "\tout_o = dec_dense_o(decoder_outputs)\n",
    "\tout_q = dec_dense_q(decoder_outputs)\n",
    "\tout_p = dec_dense_p(decoder_outputs)\n",
    "\t\n",
    "\tmodel = Model([enc_in_o, enc_in_q, enc_in_p, dec_in_o, dec_in_q, dec_in_p], [out_o, out_q, out_p])\n",
    "\t\n",
    "\t# define inference encoder\n",
    "\tencoder_model = Model([enc_in_o, enc_in_q, enc_in_p], encoder_states)\n",
    "\t\n",
    "\t# define inference decoder\n",
    "\tdecoder_state_input_h = Input(shape=(n_units,))\n",
    "\tdecoder_state_input_c = Input(shape=(n_units,))\n",
    "\tdecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\tdecoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\tdecoder_states = [state_h, state_c]\n",
    "\t#out_o = TimeDistributed(Dense(1, activation='relu'))(decoder_outputs)#act relu\n",
    "\t#out_q = TimeDistributed(Dense(1, activation='sigmoid'))(decoder_outputs)\n",
    "\t#out_p = TimeDistributed(Dense(dim_p, activation='softmax'))(decoder_outputs)\n",
    "\tout_o = dec_dense_o(decoder_outputs)\n",
    "\tout_q = dec_dense_q(decoder_outputs)\n",
    "\tout_p = dec_dense_p(decoder_outputs)\n",
    "\n",
    "\tdecoder_model = Model([dec_in_o, dec_in_q, dec_in_p] + decoder_states_inputs, [out_o, out_q, out_p] + decoder_states)\n",
    "\t# return all models\n",
    "\treturn model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "# generate target given source sequence\n",
    "def predict_sequence(infenc, infdec, src_o, src_q, src_p, n_steps, cardinality_o, cardinality_q, cardinality_p):\n",
    "\t# encode\n",
    "\tstate = infenc.predict([src_o, src_q, src_p])\n",
    "\t# start of sequence input\n",
    "\ttarget_o = np.array([0.0 for _ in range(cardinality_o)]).reshape(1, 1, cardinality_o)\n",
    "\ttarget_q = np.array([0.0 for _ in range(cardinality_q)]).reshape(1, 1, cardinality_q)\n",
    "\t#target_p = 0\n",
    "\ttarget_p = np.array([0.0 for _ in range(cardinality_p)]).reshape(1, 1, cardinality_p)\n",
    "\t# collect predictions\n",
    "\toutput = list()\n",
    "\tfor t in range(n_steps):\n",
    "\t\t# predict next char\n",
    "\t\t#print(target_o.shape)\n",
    "\t\t#print(target_q.shape)\n",
    "\t\t#print(target_p.shape)\n",
    "\t\t#print(state[0].shape)\n",
    "\t\to, q, p, h, c = infdec.predict([target_o, target_q, target_p] + state)\n",
    "\t\t#print(a)\n",
    "\t\t# store prediction\n",
    "\t\toutput.append(o[0,0,:])\n",
    "\t\toutput.append(q[0,0,:])\n",
    "\t\toutput.append(p[0,0,:])\n",
    "\t\t# update state\n",
    "\t\tstate = [h, c]\n",
    "\t\t# update target sequence\n",
    "\t\ttarget_o = o\n",
    "\t\ttarget_q = q\n",
    "\t\ttarget_p = p\n",
    "\treturn np.array(output)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "\treturn [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "#create list with window length sequences of list a data\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "#create directory for offset, quarterlength one hot encoding\n",
    "def qldir(m_o, qi):\n",
    "    fullql = []\n",
    "    for i in range(0, int(m_o), 1):\n",
    "        #j = str(i)   \n",
    "        fullql.append(i+.0) \n",
    "        fullql.append(i+.25)\n",
    "        fullql.append(i+.33)\n",
    "        fullql.append(i+.5)\n",
    "        fullql.append(i+.66)\n",
    "        fullql.append(i+.75)\n",
    "    fullql.append(m_o)\n",
    "    fullql.append(m_o+.25)\n",
    "    fullql[10] = 1.66\n",
    "    \n",
    "    if (qi == True):\n",
    "        r_dict = dict((c, i) for i, c in enumerate(fullql))\n",
    "    else:\n",
    "        r_dict = dict((i, c) for i, c in enumerate(fullql))\n",
    "    \n",
    "    return r_dict\n",
    "\n",
    "#generate train inputs and outputs while one hot encoding pitch and padding for seq2seq\n",
    "def generatorex(features1, features2, features3, seq_length, ft_o, ft_q, ft_p, m_o, m_q, batch_size):\n",
    "    # Create empty arrays to contain batch of features and labels# \n",
    "    q_to_i = qldir(m_o, True)\n",
    "    batch_features1 = np.zeros((batch_size, seq_length, ft_o))\n",
    "    batch_features2 = np.zeros((batch_size, seq_length, ft_q))\n",
    "    batch_features3 = np.zeros((batch_size, seq_length, ft_p))\n",
    "    batch_feat_pad1 = np.zeros((batch_size, seq_length, ft_o))\n",
    "    batch_feat_pad2 = np.zeros((batch_size, seq_length, ft_q))\n",
    "    batch_feat_pad3 = np.zeros((batch_size, seq_length, ft_p))\n",
    "    i = 0\n",
    "    while True:\n",
    "        for b in range(batch_size):\n",
    "            batch_features1[b] = to_categorical([q_to_i[ql[0]] for ql in features1[i]], num_classes=ft_o)\n",
    "            batch_features2[b] = to_categorical([q_to_i[ql[0]] for ql in features2[i]], num_classes=ft_q)\n",
    "            batch_features3[b] = to_categorical(features3[i], num_classes=ft_p)\n",
    "            batch_feat_pad1[b] = to_categorical(np.append([m_o+.25], [q_to_i[ql[0]] for ql in features1[i][:-1]]).reshape(seq_length, 1), num_classes=ft_o)\n",
    "            batch_feat_pad2[b] = to_categorical(np.append([m_q+.25], [q_to_i[ql[0]] for ql in features2[i][:-1]]).reshape(seq_length, 1), num_classes=ft_q)\n",
    "            batch_feat_pad3[b] = to_categorical(np.append([0], features3[i][:-1]).reshape(seq_length, 1), num_classes=ft_p)\n",
    "            i += 1\n",
    "            if (i == len(features1)):\n",
    "                i=0\n",
    "        #print(batch_features, batch_labels)\n",
    "        yield [batch_features1, batch_features2, batch_features3, batch_feat_pad1, batch_feat_pad2, batch_feat_pad3], [batch_features1, batch_features2, batch_features3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:26.316642Z",
     "iopub.status.busy": "2021-02-15T21:07:26.316080Z",
     "iopub.status.idle": "2021-02-15T21:07:30.514489Z",
     "shell.execute_reply": "2021-02-15T21:07:30.513610Z"
    },
    "papermill": {
     "duration": 4.207165,
     "end_time": "2021-02-15T21:07:30.514611",
     "exception": false,
     "start_time": "2021-02-15T21:07:26.307446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "stream_list = []\n",
    "\n",
    "for path, subdirectories, files in os.walk('/kaggle/input/data-rock/kag'):\n",
    "    for name in files:\n",
    "        with open(os.path.join(path, name), 'r') as f: \n",
    "            reader = csv.reader(f)\n",
    "            sub_list = [list(map(float,rec)) for rec in csv.reader(f, delimiter=',')]\n",
    "            stream_list = stream_list + sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:30.540474Z",
     "iopub.status.busy": "2021-02-15T21:07:30.535069Z",
     "iopub.status.idle": "2021-02-15T21:07:31.079389Z",
     "shell.execute_reply": "2021-02-15T21:07:31.078846Z"
    },
    "papermill": {
     "duration": 0.558589,
     "end_time": "2021-02-15T21:07:31.079505",
     "exception": false,
     "start_time": "2021-02-15T21:07:30.520916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create seperate data structures for each variable (offset, quarterlength, pitch)\n",
    "#normalise offset and quarterlength\n",
    "offs = []\n",
    "qlngth = []\n",
    "ptch = []\n",
    "\n",
    "max_o = 600.0\n",
    "max_q = 50.0\n",
    "\n",
    "offsb = max(element[0] for element in stream_list if element[0]<=max_o)\n",
    "qlngthb = max(element[1] for element in stream_list if element[1]<=max_q)\n",
    "#ptchb = 127.0\n",
    "\n",
    "for row in stream_list:\n",
    "    if (row[0] <= max_o and row[1] <= max_q):\n",
    "        offs.append(trunc(row[0]*100)/100)\n",
    "        qlngth.append(trunc(row[1]*100)/100)\n",
    "        ptch.append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:31.177629Z",
     "iopub.status.busy": "2021-02-15T21:07:31.176476Z",
     "iopub.status.idle": "2021-02-15T21:07:31.180441Z",
     "shell.execute_reply": "2021-02-15T21:07:31.179949Z"
    },
    "papermill": {
     "duration": 0.094454,
     "end_time": "2021-02-15T21:07:31.180545",
     "exception": false,
     "start_time": "2021-02-15T21:07:31.086091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  465352\n"
     ]
    }
   ],
   "source": [
    "#divide the sets in sequences of specific length \n",
    "dtlngth=len(offs)\n",
    "n_features_o = int(max_o)*6+2\n",
    "n_features_q = int(max_q)*6+2\n",
    "n_features_p = 127+1\n",
    "seq_length = 4#100 groups of 3\n",
    "\n",
    "dataX1_o = rolling_window(np.asarray(offs), seq_length)\n",
    "dataX1_q = rolling_window(np.asarray(qlngth), seq_length)\n",
    "dataX1_p = rolling_window(np.asarray(ptch), seq_length)\n",
    "\n",
    "n_patterns = len(dataX1_p)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:31.200377Z",
     "iopub.status.busy": "2021-02-15T21:07:31.199736Z",
     "iopub.status.idle": "2021-02-15T21:07:31.203705Z",
     "shell.execute_reply": "2021-02-15T21:07:31.203037Z"
    },
    "papermill": {
     "duration": 0.016204,
     "end_time": "2021-02-15T21:07:31.203836",
     "exception": false,
     "start_time": "2021-02-15T21:07:31.187632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reshape inputs to be [samples, time steps, features]\n",
    "dataX1_o = np.reshape(dataX1_o, (dtlngth - seq_length + 1, seq_length, 1))\n",
    "dataX1_q = np.reshape(dataX1_q, (dtlngth - seq_length + 1, seq_length, 1))\n",
    "dataX1_p = np.reshape(dataX1_p, (dtlngth - seq_length + 1, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:31.224420Z",
     "iopub.status.busy": "2021-02-15T21:07:31.223512Z",
     "iopub.status.idle": "2021-02-15T21:07:31.227146Z",
     "shell.execute_reply": "2021-02-15T21:07:31.226570Z"
    },
    "papermill": {
     "duration": 0.016431,
     "end_time": "2021-02-15T21:07:31.227271",
     "exception": false,
     "start_time": "2021-02-15T21:07:31.210840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Patterns:  46535\n"
     ]
    }
   ],
   "source": [
    "#divide data in train and validation sets\n",
    "split_i = n_patterns*10 // 100\n",
    "\n",
    "dataX1_o_v = dataX1_o[-split_i:]\n",
    "dataX1_o = dataX1_o[:-split_i]\n",
    "\n",
    "dataX1_q_v = dataX1_q[-split_i:]\n",
    "dataX1_q = dataX1_q[:-split_i]\n",
    "\n",
    "dataX1_p_v = dataX1_p[-split_i:]\n",
    "dataX1_p = dataX1_p[:-split_i]\n",
    "\n",
    "print (\"Validation Patterns: \", split_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:31.247750Z",
     "iopub.status.busy": "2021-02-15T21:07:31.247152Z",
     "iopub.status.idle": "2021-02-15T21:07:32.288123Z",
     "shell.execute_reply": "2021-02-15T21:07:32.287505Z"
    },
    "papermill": {
     "duration": 1.053604,
     "end_time": "2021-02-15T21:07:32.288238",
     "exception": false,
     "start_time": "2021-02-15T21:07:31.234634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure problem\n",
    "n_steps_out = seq_length\n",
    "# define model\n",
    "train, infenc, infdec = define_models(n_features_o, n_features_q, n_features_p, 128)\n",
    "train.compile(optimizer='adam', loss={'tr_out_o': 'categorical_crossentropy', 'tr_out_q': 'categorical_crossentropy', 'tr_out_p': 'categorical_crossentropy'},\n",
    " metrics={'tr_out_o': 'accuracy', 'tr_out_q': 'accuracy', 'tr_out_p': 'accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:07:32.309415Z",
     "iopub.status.busy": "2021-02-15T21:07:32.308736Z",
     "iopub.status.idle": "2021-02-15T21:40:37.329284Z",
     "shell.execute_reply": "2021-02-15T21:40:37.328722Z"
    },
    "papermill": {
     "duration": 1985.033445,
     "end_time": "2021-02-15T21:40:37.329416",
     "exception": false,
     "start_time": "2021-02-15T21:07:32.295971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "775/775 [==============================] - 395s 510ms/step - loss: 12.5674 - tr_out_o_loss: 7.2881 - tr_out_q_loss: 1.7968 - tr_out_p_loss: 3.4825 - tr_out_o_accuracy: 0.0215 - tr_out_q_accuracy: 0.5224 - tr_out_p_accuracy: 0.1495\n",
      "Epoch 2/5\n",
      "775/775 [==============================] - 393s 507ms/step - loss: 6.3118 - tr_out_o_loss: 3.5793 - tr_out_q_loss: 0.9072 - tr_out_p_loss: 1.8253 - tr_out_o_accuracy: 0.5432 - tr_out_q_accuracy: 0.7355 - tr_out_p_accuracy: 0.4830\n",
      "Epoch 3/5\n",
      "775/775 [==============================] - 395s 510ms/step - loss: 2.7456 - tr_out_o_loss: 1.2923 - tr_out_q_loss: 0.5218 - tr_out_p_loss: 0.9315 - tr_out_o_accuracy: 0.7626 - tr_out_q_accuracy: 0.8476 - tr_out_p_accuracy: 0.7429\n",
      "Epoch 4/5\n",
      "775/775 [==============================] - 396s 511ms/step - loss: 1.5193 - tr_out_o_loss: 0.7503 - tr_out_q_loss: 0.3010 - tr_out_p_loss: 0.4680 - tr_out_o_accuracy: 0.8335 - tr_out_q_accuracy: 0.9164 - tr_out_p_accuracy: 0.8795\n",
      "Epoch 5/5\n",
      "775/775 [==============================] - 399s 514ms/step - loss: 0.9542 - tr_out_o_loss: 0.4985 - tr_out_q_loss: 0.1849 - tr_out_p_loss: 0.2708 - tr_out_o_accuracy: 0.8806 - tr_out_q_accuracy: 0.9519 - tr_out_p_accuracy: 0.9350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdbe9fa4550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "train.fit(generatorex(dataX1_o, dataX1_q, dataX1_p, seq_length, n_features_o, n_features_q, n_features_p, max_o, max_q, batch_size=540), epochs = 5, \n",
    "          steps_per_epoch= (dtlngth-split_i) // 540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T21:40:39.292753Z",
     "iopub.status.busy": "2021-02-15T21:40:39.292182Z",
     "iopub.status.idle": "2021-02-15T21:40:42.473388Z",
     "shell.execute_reply": "2021-02-15T21:40:42.474013Z"
    },
    "papermill": {
     "duration": 4.184201,
     "end_time": "2021-02-15T21:40:42.474177",
     "exception": false,
     "start_time": "2021-02-15T21:40:38.289976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_o=[188.], y_o=188.0, X_q=[0.33], y_q=0.33, X_p=[76.], y_p=[76]\n",
      "X_o=[188.], y_o=188.0, X_q=[0.33], y_q=0.33, X_p=[83.], y_p=[83]\n",
      "X_o=[188.], y_o=188.0, X_q=[0.33], y_q=0.33, X_p=[88.], y_p=[45]\n",
      "X_o=[188.], y_o=188.0, X_q=[0.33], y_q=0.33, X_p=[45.], y_p=[57]\n",
      "\n",
      "X_o=[14.5], y_o=14.5, X_q=[0.5], y_q=0.5, X_p=[33.], y_p=[33]\n",
      "X_o=[15.], y_o=15.0, X_q=[0.5], y_q=0.5, X_p=[45.], y_p=[45]\n",
      "X_o=[15.], y_o=15.0, X_q=[0.5], y_q=0.5, X_p=[52.], y_p=[52]\n",
      "X_o=[15.], y_o=15.0, X_q=[0.5], y_q=0.5, X_p=[33.], y_p=[33]\n",
      "\n",
      "X_o=[66.66], y_o=67.0, X_q=[0.25], y_q=0.25, X_p=[68.], y_p=[68]\n",
      "X_o=[67.], y_o=67.0, X_q=[0.25], y_q=0.25, X_p=[59.], y_p=[59]\n",
      "X_o=[67.], y_o=67.0, X_q=[0.25], y_q=0.25, X_p=[64.], y_p=[64]\n",
      "X_o=[67.], y_o=67.0, X_q=[0.25], y_q=0.25, X_p=[68.], y_p=[68]\n",
      "\n",
      "X_o=[512.], y_o=512.0, X_q=[2.25], y_q=2.25, X_p=[60.], y_p=[60]\n",
      "X_o=[512.], y_o=512.0, X_q=[2.25], y_q=2.25, X_p=[64.], y_p=[64]\n",
      "X_o=[512.], y_o=512.0, X_q=[0.5], y_q=0.5, X_p=[55.], y_p=[55]\n",
      "X_o=[512.], y_o=512.0, X_q=[0.5], y_q=0.5, X_p=[60.], y_p=[62]\n",
      "\n",
      "X_o=[82.], y_o=82.0, X_q=[0.66], y_q=0.66, X_p=[49.], y_p=[56]\n",
      "X_o=[82.], y_o=82.0, X_q=[0.66], y_q=0.66, X_p=[56.], y_p=[49]\n",
      "X_o=[82.], y_o=82.0, X_q=[0.66], y_q=0.66, X_p=[37.], y_p=[49]\n",
      "X_o=[82.25], y_o=82.0, X_q=[0.25], y_q=0.25, X_p=[73.], y_p=[73]\n",
      "\n",
      "X_o=[314.], y_o=314.0, X_q=[0.25], y_q=0.25, X_p=[76.], y_p=[76]\n",
      "X_o=[314.], y_o=314.0, X_q=[0.25], y_q=0.25, X_p=[81.], y_p=[81]\n",
      "X_o=[314.], y_o=314.0, X_q=[0.5], y_q=0.5, X_p=[49.], y_p=[49]\n",
      "X_o=[314.], y_o=314.0, X_q=[0.5], y_q=0.5, X_p=[56.], y_p=[56]\n",
      "\n",
      "X_o=[186.33], y_o=22.66, X_q=[0.25], y_q=0.25, X_p=[73.], y_p=[73]\n",
      "X_o=[186.33], y_o=186.66, X_q=[0.25], y_q=0.25, X_p=[76.], y_p=[76]\n",
      "X_o=[186.33], y_o=186.66, X_q=[0.25], y_q=0.25, X_p=[81.], y_p=[81]\n",
      "X_o=[186.66], y_o=186.66, X_q=[0.25], y_q=0.25, X_p=[71.], y_p=[71]\n",
      "\n",
      "X_o=[269.], y_o=269.0, X_q=[0.25], y_q=0.25, X_p=[64.], y_p=[64]\n",
      "X_o=[269.], y_o=269.0, X_q=[0.25], y_q=0.25, X_p=[69.], y_p=[69]\n",
      "X_o=[269.33], y_o=269.0, X_q=[0.25], y_q=0.25, X_p=[61.], y_p=[61]\n",
      "X_o=[269.33], y_o=269.0, X_q=[0.25], y_q=0.25, X_p=[64.], y_p=[64]\n",
      "\n",
      "X_o=[514.], y_o=514.0, X_q=[0.25], y_q=0.25, X_p=[69.], y_p=[69]\n",
      "X_o=[514.], y_o=514.0, X_q=[0.5], y_q=0.25, X_p=[81.], y_p=[67]\n",
      "X_o=[514.25], y_o=514.0, X_q=[0.25], y_q=0.25, X_p=[67.], y_p=[67]\n",
      "X_o=[514.5], y_o=514.0, X_q=[0.25], y_q=0.25, X_p=[67.], y_p=[67]\n",
      "\n",
      "X_o=[38.], y_o=38.0, X_q=[0.25], y_q=0.25, X_p=[71.], y_p=[71]\n",
      "X_o=[38.], y_o=38.0, X_q=[0.25], y_q=0.25, X_p=[76.], y_p=[76]\n",
      "X_o=[38.], y_o=38.0, X_q=[0.25], y_q=0.25, X_p=[80.], y_p=[80]\n",
      "X_o=[38.25], y_o=38.25, X_q=[0.25], y_q=0.25, X_p=[71.], y_p=[80]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spot check some examples\n",
    "ql_to_int = qldir(max_o, True)\n",
    "int_to_ql = qldir(max_o, False)\n",
    "for _ in range(10):\n",
    "    i = randint(1, 10000)\n",
    "    X1_o = np.reshape(to_categorical([ql_to_int[ql[0]] for ql in dataX1_o_v[i]], num_classes=n_features_o), (1, seq_length, n_features_o))\n",
    "    X1_q = np.reshape(to_categorical([ql_to_int[ql[0]] for ql in dataX1_q_v[i]], num_classes=n_features_q), (1, seq_length, n_features_q))\n",
    "    X1_p = np.reshape(to_categorical(dataX1_p_v[i], num_classes=n_features_p), (1, seq_length, n_features_p))\n",
    "    target = predict_sequence(infenc, infdec, X1_o, X1_q, X1_p, n_steps_out, n_features_o, n_features_q, n_features_p)\n",
    "    for j in range(seq_length):\n",
    "        print('X_o=%s, y_o=%s, X_q=%s, y_q=%s, X_p=%s, y_p=%s' % (\n",
    "            dataX1_o_v[i][j], int_to_ql[one_hot_decode([target[3*j]])[0]], \n",
    "            dataX1_q_v[i][j], int_to_ql[one_hot_decode([target[3*j+1]])[0]], \n",
    "            dataX1_p_v[i][j], one_hot_decode([target[3*j+2]])))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2008.092869,
   "end_time": "2021-02-15T21:40:43.538541",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-15T21:07:15.445672",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
